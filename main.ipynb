{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La distribución de la variable objetivo es:\n",
      " 0    3099\n",
      "1     557\n",
      "Name: TenYearCHD, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.dropna()\n",
    "dataset =None\n",
    "print(\"La distribución de la variable objetivo es:\\n\",df['TenYearCHD'].value_counts())\n",
    "X = df.drop(['TenYearCHD'], axis=1).to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna sex no parece provenir de una distribución normal\n",
      "La columna age no parece provenir de una distribución normal\n",
      "La columna education no parece provenir de una distribución normal\n",
      "La columna currentSmoker no parece provenir de una distribución normal\n",
      "La columna cigsPerDay no parece provenir de una distribución normal\n",
      "La columna BPMeds no parece provenir de una distribución normal\n",
      "La columna prevalentStroke no parece provenir de una distribución normal\n",
      "La columna prevalentHyp no parece provenir de una distribución normal\n",
      "\n",
      "Las varaibles significativas ['sex', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'prevalentStroke', 'prevalentHyp']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "\n",
    "variables_significativas =[]\n",
    "pca = PCA(n_components=8)\n",
    "\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    stat, p = shapiro(X[:,i])\n",
    "    alpha = 0.05\n",
    "    variables_significativas.append(df.columns[i])\n",
    "    if p > alpha:\n",
    "        print(f'La columna {df.columns[i]} parece provenir de una distribución normal')\n",
    "    else:\n",
    "        print(f'La columna {df.columns[i]} no parece provenir de una distribución normal')\n",
    "        \n",
    "print(\"\\nLas varaibles significativas\",variables_significativas)\n",
    "variables_significativas.append('TenYearCHD')\n",
    "\n",
    "dataset = df[variables_significativas]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La nueva distribución de la variable objetivo es:\n",
      " 0    3099\n",
      "1    3099\n",
      "Name: TenYearCHD, dtype: int64\n",
      "\n",
      "Precisión del modelo: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "y = dataset['TenYearCHD']\n",
    "x = dataset.drop(['TenYearCHD'], axis=1)\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "x,y = sm.fit_resample(x, y)\n",
    "print(\"La nueva distribución de la variable objetivo es:\\n\",y.value_counts())\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "logreg.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test_poly)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nPrecisión del modelo: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
